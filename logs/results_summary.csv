Run, Accuracy, FPR, F1 Score,F1-test, Preprocessing, Feature, Model, Notes
0,0.872474747474747,0.121951219512195,0.762352941176471,0.8955643914,"Removed Urls, Removed non-alphabetic characters, NLTK stopwords",Bow,MultinomialNB,
0.1,0.88510101010101,0.090452261306533,0.799116997792495,0.895222106685909,Custom stopwords,Bow,MultinomialNB,
0.1.1,0.869949494949495,0.128329297820823,0.777537796976242,,Custom stopwords,BoW on full set,MultinomialNB,
0.2,0.928282828282828,0.057255676209279,0.870556061987238,0.886800721389211,Removing username,Used full train set for training,MultinomialNB,
0.3,0.928156565656566,0.057255676209279,0.870357712462975,0.8955643914,sms extractions,Used full train set for training,MultinomialNB,
0.4,0.928282828282828,0.056762092793682,0.870615034168565,0.885328885810059,correcting mis-spellings,Used full train set for training,Undersampling training data,
0.4.1,0.89280303030303,0.022704837117473,0.82345601996257,0.867071174963912,correcting mis-spellings,Used full train set for training,MultinomialNB,
0.5,0.927020202020202,0.056268509378085,0.868696047251249,0.883970739423941,Removed twitter pic urls,Used full train set for training,MultinomialNB,
0.6,0.921969696969697,0.056762092793682,0.860810810810811,0.879544540363254,Lemmatization,Used full train set for training,MultinomialNB,
0.7,0.91969696969697,0.053307008884502,0.85778175313059,0.870070989112258,Split Camel case hashtags,Used full train set for training,MultinomialNB,
0.7.2,0.922979797979798,0.054787759131293,0.862612612612613,0.871422594308083,Cleaned URLs,Used full train set for training,MultinomialNB,
0.7.4,0.919444444444444,0.054787759131293,0.857206803939122,,Additional URL cleanup,Used full train set for training,MultinomialNB,
0.7.5,0.919444444444444,0.054787759131293,0.857206803939122,,URL cleanup,Used full train set for training,MultinomialNB,
0.7.6a,0.922727272727273,0.05528134254689,0.862162162162162,,,Used full train set for training,MultinomialNB,
0.7.6b,0.973232323232323,0.048864758144126,0.947860304968028,,,Used full train set for training,Logistic Regression,
0.8,0.908207070707071,0.057749259624877,0.84004400440044,0.876056181061124,Wordninja,Used full train set for training,MultinomialNB,
0.9a,0.913636363636364,0.052319842053307,0.848806366047745,,PorterStemmer,Used full train set for training,MultinomialNB,
0.9b,0.971085858585859,0.049851924975321,0.943858788918853,0.855143054009646,PorterStemmer,Used full train set for training,Logistic Regression,
0.10,0.4486075949367089,nan,0.0,,,TextBlob baseline,
0.10,0.32651515151515154,0.7359328726554788,0.16708307307932543,,,TextBlob baseline,
0.11,0.7441919191919192,1.0,0.0,,,SVM,
1.0,0.8898989898989899,0.22902270483711748,0.7817817817817818,0.836748601404142,Keras Tokenizer on cleaned,,Keras LSTM with glove100d,
